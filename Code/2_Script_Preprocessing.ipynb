{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general liraries\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm import tqdm # to check time progress\n",
    "import os # to connect\n",
    "\n",
    "# to check duplicates\n",
    "from PIL import Image\n",
    "!pip install imagehash\n",
    "import imagehash\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.image as mpimg # read images as array\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "!pip install imbalanced-learn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxKhMqOvg0Wb",
    "tags": []
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3s6Fp6mkxV1M"
   },
   "outputs": [],
   "source": [
    "# define folder path & create lists with file names\n",
    "folder = os.path.join(\"filtered_cropped_images_saved/\")\n",
    "filelist = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7451\n"
     ]
    }
   ],
   "source": [
    "print(len(filelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49GWi3RL6l1-",
    "outputId": "4a4f4cd8-2282-4c5e-988c-edb976de6a97"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7451/7451 [00:00<00:00, 608188.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create an array with filenames & labels from dataset folder\n",
    "X_1 = []\n",
    "y_1 = []\n",
    "\n",
    "for file in tqdm(filelist):\n",
    "    try:\n",
    "        label = re.search(r'_(.*?)_', file).group(1) # extract the label from the filename using regex\n",
    "        if label in ['gametocyte', 'ring', 'schizont', 'trophozoite']:\n",
    "            label = 'infected'\n",
    "        elif label in [\"red blood cell\"]: \n",
    "            label = \"uninfected\"  # some files are not readable e.g. \"cropped_images_train/.DS_Store\"\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        X_1.append(file)\n",
    "        y_1.append(label)\n",
    "\n",
    "        # if no label is found in the filename, skip this file\n",
    "    except AttributeError:\n",
    "        #print(f\"no label found in filename: {file}\")\n",
    "        continue\n",
    "\n",
    "X_1 = np.array(X_1)\n",
    "y_1 = np.array(y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oEqOsoLnvL1s",
    "outputId": "33993406-a738-4283-e815-25cb5a672231"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images in Array:  7451 7451\n",
      "Number of images per label:  [('infected', 2451), ('uninfected', 5000)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Images in Array: \", len(X_1), len(y_1))\n",
    "print(\"Number of images per label: \" , sorted(Counter(y_1).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKmFJ8ik1DlB"
   },
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBZrOpXmvlzg"
   },
   "source": [
    "Find and eliminate Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xLlK3d_mToKj",
    "outputId": "1d1529de-a4d7-4866-f1a4-a4268a8c7e6a"
   },
   "outputs": [],
   "source": [
    "# Function to identify and remove duplicates\n",
    "def remove_duplicates(directory, file_names, label_names):\n",
    "    image_hashes = {}\n",
    "    duplicates = []\n",
    "    updated_file_names = []\n",
    "    updated_label_names = []\n",
    "    num_non_existing = 0\n",
    "  \n",
    "    for i in tqdm(range(len(file_names))):\n",
    "        filename = file_names[i]\n",
    "        image_path = os.path.join(directory, filename)\n",
    "        if not os.path.exists(image_path):\n",
    "            num_non_existing += 1\n",
    "            continue\n",
    "\n",
    "        with Image.open(image_path) as img:\n",
    "            img_hash = imagehash.average_hash(img, hash_size=128)\n",
    "\n",
    "        if img_hash in image_hashes:\n",
    "            duplicates.append((image_path, image_hashes[img_hash]))\n",
    "        else:\n",
    "            image_hashes[img_hash] = image_path\n",
    "            updated_file_names.append(file_names[i])\n",
    "            updated_label_names.append(label_names[i])\n",
    "\n",
    "    print(\"Number of non-existing image paths:\", num_non_existing)\n",
    "    return np.array(updated_file_names), np.array(updated_label_names), duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "id": "qMCrQfbNPbuz",
    "outputId": "b2834d09-413f-45f1-b701-94ff8e29851c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7451/7451 [00:33<00:00, 224.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-existing image paths: 0\n",
      "7451 7451\n",
      "[('infected', 2451), ('uninfected', 5000)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Call the remove_duplicates function for training dataset\n",
    "X_cleaned1, y_cleaned1, duplicates = remove_duplicates(folder, X_1, y_1)\n",
    "\n",
    "# Print the cleaned X_train and y_train\n",
    "print(len(X_cleaned1), len(y_cleaned1))\n",
    "print(sorted(Counter(y_cleaned1).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates:  0\n"
     ]
    }
   ],
   "source": [
    "# Show how many duplicates were found\n",
    "print(\"Number of duplicates: \", len(duplicates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jN6RqtDtS9Qu"
   },
   "source": [
    "Create binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G7hSnT5qwjCs",
    "outputId": "98de30b2-5d35-4f03-d2b2-246bda844933"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7451\n",
      "[(0, 2451), (1, 5000)]\n"
     ]
    }
   ],
   "source": [
    "# encoding labels as 1 = infected, 0 = uninfected\n",
    "le = LabelEncoder()\n",
    "y_cleaned1 = le.fit_transform(y_cleaned1)\n",
    "\n",
    "print(len(y_cleaned1))\n",
    "print(sorted(Counter(y_cleaned1).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnFf5ppfS8qf"
   },
   "source": [
    "Shuffle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3cl6Yias3ZeM"
   },
   "outputs": [],
   "source": [
    "# saving the shuffled file.\n",
    "X_cleaned, y_cleaned = shuffle(X_cleaned1, y_cleaned1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "099goppwTBdD"
   },
   "source": [
    "Create Test, Training and Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KBVe5jFITJUN"
   },
   "outputs": [],
   "source": [
    "# Split data by label\n",
    "infected_indices = np.where(y_cleaned == 0)[0]\n",
    "uninfected_indices = np.where(y_cleaned == 1)[0]\n",
    "\n",
    "# Get arrays only for according classes (for infected and uninfected) based on indecis\n",
    "y_infected = y_cleaned[infected_indices]\n",
    "X_infected = X_cleaned[infected_indices]\n",
    "\n",
    "X_uninfected = X_cleaned[uninfected_indices]\n",
    "y_uninfected = y_cleaned[uninfected_indices]\n",
    "\n",
    "# Split infected data into train, validation, and test sets\n",
    "X_train_infected, X_val_infected, y_train_infected, y_val_infected = train_test_split(X_infected, y_infected, test_size=0.4, random_state=42)\n",
    "X_val_infected, X_test_infected, y_val_infected, y_test_infected = train_test_split(X_val_infected, y_val_infected, test_size=0.5, random_state=42)\n",
    "\n",
    "# Split uninfected data into train, validation, and test sets\n",
    "X_train_uninfected, X_val_uninfected, y_train_uninfected, y_val_uninfected = train_test_split(X_uninfected, y_uninfected, test_size=0.4, random_state=42)\n",
    "X_val_uninfected, X_test_uninfected, y_val_uninfected, y_test_uninfected = train_test_split(X_val_uninfected, y_val_uninfected, test_size=0.5, random_state=42)\n",
    "\n",
    "# Merge data back together\n",
    "X_train = np.concatenate([X_train_infected, X_train_uninfected])\n",
    "y_train = np.concatenate([y_train_infected, y_train_uninfected])\n",
    "\n",
    "X_val = np.concatenate([X_val_infected, X_val_uninfected])\n",
    "y_val = np.concatenate([y_val_infected, y_val_uninfected])\n",
    "\n",
    "X_test = np.concatenate([X_test_infected, X_test_uninfected])\n",
    "y_test = np.concatenate([y_test_infected, y_test_uninfected])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5Akww1ETVThr"
   },
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "X_train, y_train  = shuffle(X_train, y_train)\n",
    "X_val, y_val= shuffle(X_val, y_val)\n",
    "X_test, y_test = shuffle(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GtD-dwgyVQcP",
    "outputId": "b9d99dd9-8448-4bc4-f1a2-9cfa22964519"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Items in Training Set:  4470 4470\n",
      "Distribution of Labels in Training Set:  [(0, 1470), (1, 3000)]\n",
      "Number of Items in Validation Set:  1490 1490\n",
      "Distribution of Labels in Validation Set:  [(0, 490), (1, 1000)]\n",
      "Number of Items in Test Set:  1491 1491\n",
      "Distribution of Labels in Test Set:  [(0, 491), (1, 1000)]\n"
     ]
    }
   ],
   "source": [
    "# check length and class size for each set\n",
    "print(\"Number of Items in Training Set: \", len(X_train), len(y_train))\n",
    "print(\"Distribution of Labels in Training Set: \", sorted(Counter(y_train).items()))\n",
    "print(\"Number of Items in Validation Set: \",len(X_val), len(y_val))\n",
    "print(\"Distribution of Labels in Validation Set: \", sorted(Counter(y_val).items()))\n",
    "print(\"Number of Items in Test Set: \",len(X_test), len(y_test))\n",
    "print(\"Distribution of Labels in Test Set: \", sorted(Counter(y_test).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final numpy arrays of filenames and labels\n",
    "np.save('Image Numpys/y_train', y_train)\n",
    "np.save('Image Numpys/X_train', X_train)\n",
    "np.save('Image Numpys/y_test', y_test)\n",
    "np.save('Image Numpys/X_test', X_test)\n",
    "np.save('Image Numpys/y_val', y_val)\n",
    "np.save('Image Numpys/X_val', X_val)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "VxKhMqOvg0Wb",
    "YWA_FnWaM_x-",
    "_MRrRjG1gttc",
    "jSaF0adLgxhD",
    "JffKlKZ3s6Hf",
    "bAi_IEYd8u9T",
    "puaJ1hL4S5Nh"
   ],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
